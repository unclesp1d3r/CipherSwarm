---
description: 
globs: tests/**/*.py
alwaysApply: false
---
## Principles

- Use `pytest` only, no unittest or nose.
- Prefer fixtures over mocks when integrating components.
- All test DB operations must use the `__async_session__` fixture to ensure compatibility with SQLAlchemy 2.0 async ORM.
- All new service logic must have corresponding tests in `tests/services/`.
- Avoid integration tests in unit test directories.

## Cursor Guidance

- Use descriptive function names (`test_assign_agent_to_session_succeeds()`).
- Group related tests into modules that mirror `app/` structure.
- Use `async def` with `pytest-asyncio`. Decorators are not needed unless switching to non-default modes.
- Only import `from app.services.X` or `from app.models.X` ‚Äî don‚Äôt use relative imports.

- Minimum required test coverage: **80%**
- Use `pytest --cov=app --cov-report=term-missing` in all coverage reports
- Report coverage deltas in CI (or log locally if airgapped)

- ‚úÖ Use `polyfactory` for generating test data in service, model, and route tests. See (Polyfactory Documentation)[https://polyfactory.litestar.dev/latest/]

  - Use `polyfactory.create_async()` only. Do not use `.build()`, `SubFactory`, or `sync` methods. All test data must be persisted using an active async SQLAlchemy session.
  - Define all factories in `tests/factories/`.
  - Reuse shared factories across test files.
  - Avoid manually constructing ORM or Pydantic objects in tests unless necessary.
  - Keep factory defaults minimal ‚Äî override fields in tests as needed.

- ‚úÖ Use `pytest-postgresql` to run tests against isolated PostgreSQL instances.

  - Do not use SQLite or in-memory DBs unless explicitly required.
  - Define shared test schemas and data fixtures in `conftest.py`.

- ‚úÖ Use `httpx.AsyncClient` for testing FastAPI endpoints.
  - Instantiate as: `httpx.AsyncClient(app=app, base_url="http://test")`
  - Do not use Starlette‚Äôs test client or custom wrappers.
  - Place route integration tests under `tests/api/` grouped by functional area.

---

## üß¨ Pydantic v2 Compatibility

- All Pydantic schemas must use **v2 idioms**:
  - `model_dump()` replaces `.dict()`
  - `model_validate()` replaces `.parse_obj()`
- Avoid using deprecated v1-style config like `orm_mode = True` ‚Äî instead, use the new `ConfigDict` syntax:

```python
  class MySchema(BaseModel):
      ...
      model_config = ConfigDict(from_attributes=True)
```

- For tests:
  - Validate input using `model_validate()` to simulate deserialization
  - Validate output using `model_dump()` with `mode="json"` or `mode="python"` as needed
  - Ensure all schemas round-trip without loss (input ‚Üí model ‚Üí output)

## Note: If you‚Äôre asserting schema output in tests, always use `model_dump(mode="json")` for consistency with API responses.

## Test Directory Layout

- Unit tests go under `tests/`, mirroring the `app/` structure.
  - e.g., `tests/services/`, `tests/models/`, `tests/core/`
- Integration tests go under `tests/integration/`
  - Group by feature or API version
  - e.g., `tests/integration/campaigns/`, `tests/integration/v1/`

**Do not mix unit and integration tests.**

---

## Coverage Expectations

- All HTTP endpoints must have corresponding integration tests using `httpx.AsyncClient`.
- All business logic ‚Äî especially services, validators, and helpers ‚Äî must be covered with unit tests.
- Include tests for:
  - Non-happy paths (e.g., validation failures, auth failures)
  - State transitions (e.g., cracking lifecycle)
  - Expected side effects (e.g., DB writes, notifications)
- Tests should validate real-world workflows where possible, not just inputs/outputs.

Avoid over-mocking. Prioritize realistic, layered testing grounded in the real stack.

---

## Advanced Coverage Considerations

- üåÄ **Asynchronous Side Effects**: If a route or service spawns background tasks (e.g., via `asyncio.create_task` or Celery), write tests to confirm those tasks are queued, invoked, or cause expected state changes.

- ‚öîÔ∏è **Concurrency & Race Conditions**: Simulate concurrent execution of relevant endpoints (e.g., task acquisition, job tracking) using `pytest-asyncio` with `asyncio.gather()` or `trio`. Verify consistent outcomes.

- üì¶ **Schema Drift & API Contracts**: Where endpoints return structured responses (e.g., JSON), add explicit schema validation using Pydantic models or response matchers to catch unintentional output changes.

- üîê **RBAC & Permission Boundaries**: For protected routes or admin-only actions, include both authorized and unauthorized test cases. Validate HTTP 403 behavior and prevent privilege escalation.

- üîÅ **Startup/Shutdown Events**: If your application registers services, event handlers, or startup hooks, write integration tests that validate those hooks fire and function as expected.

- üîÑ **Migration Coverage**: Include at least one test that validates all Alembic migrations apply cleanly (alembic upgrade head) in CI against a fresh DB.

---

## Linter & Static Analysis Guidelines (for /tests)

You should attempt to satisfy all linter and static analysis rules in the `/tests` directory. However:

- Do **not** waste time chasing every false-positive caused by test-specific code structures (e.g., dynamically generated test IDs, parametrization, context-dependent mocks).
- If a linter rule fails for a **legitimate test use case**:
  - ‚úÖ First, try to restructure the code to avoid the warning.
  - ‚úÖ If that‚Äôs not possible, **ask permission** before adding a `# noqa` or updating `pyproject.toml` to silence the warning globally or selectively.
  - ‚ùå Never disable test directory linting wholesale.

Linter errors in tests should be treated as **soft failures** unless they indicate real issues (e.g., unimported fixtures, unreachable code, broken decorators). Prioritize clarity and functionality over silence.
