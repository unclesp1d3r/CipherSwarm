Here’s a Skirmish-style implementation checklist for the Crackable Upload Processing Pipeline:

### 📦 Crackable Upload Plugin Pipeline — Skirmish Task Checklist

#### 🔧 Backend Models & DB

- [x] Create `HashUploadTask` model:
  - Fields: `id`, `user_id`, `filename`, `status`, `started_at`, `finished_at`, `error_count`, `hash_list_id`, `campaign_id`
- [x] Create `UploadErrorEntry` model:
  - Fields: `id`, `upload_id`, `line_number`, `raw_line`, `error_message`
- [x] Add Alembic migrations for both models

#### 🗂️ File Handling + Storage

- [ ] Create a new `UploadResourceFile` model:
  - Similar to `AttackResourceFile` except this is for the purpose of uploading a file or text blob to the bucket and then only downloaded by the processing task
  - It might be possible to use a subclass of `AttackResourceFile` to avoid duplicating code, have a specific variant of the `AttackResourceFile` model only for uploads, or to have them share a common base class.
- [ ] Return a presigned url to allow the user to upload a file or save the text blob in the `content` field of the `UploadResourceFile` model

#### 🪄 Plugin Interface & Dispatch

- [ ] Create `plugins/` folder with base interface:
  ```python
  def extract_hashes(path: Path) -> list[str]: ...
  ```
- [ ] 	Add plugins/pcap2john.py (placeholder)
- [ ] 	Add dispatcher:
    - Loads plugin based on extension
    - Validates it implements extract_hashes()
- [ ]  Raise and log `PluginExecutionError` if plugin fails

#### 🧠 Hash Parsing & Conversion
- [ ] 	Implement 
    ```python
    parse_john_line(raw_line: str) -> ParsedHashLine
    ```
	-	Validates format
	-	Extracts: `username`, `hashcat_hash`, `metadata`
- [ ] 	Add hash type guessing (use `HashGuessService` from `app.core.services.hash_guess_service`)
- [ ]	Enforce type confidence threshold before inserting
- [ ]   Create an initial reference plugin implementation to use for tests that supports the standard linux `shadow` file format using `sha512crypt` hashes. It should allow either a standard shadow file or a a combined "unshadowed" file generated by the `unshadow` tool (see [unshadow man page](https://manpages.ubuntu.com/manpages/noble/man8/unshadow.8.html) for reference). Every plugin should be a python file in the `plugins/` folder and should be a valid python module.

#### 🛠️ HashList + Campaign Creation
- [ ]	Create ephemeral HashList:
	-	Make a `AttackResourceFile` with `resource_type` `AttackResourceType.EPHEMERAL_HASH_LIST`
	-	Add a flag to the hash list: `is_unavailable`
- [ ]	Create Campaign under current user’s project
	-	Add a flag to the campaign: `is_unavailable`
- [ ]	Link both to `HashUploadTask`

#### 🔁 Task Runner + Status Updater
- [ ]	Create background task: 
    ```python
    process_uploaded_hash_file(upload_id: int)
    ```
- [ ]	Add status tracking:
	-	`pending` → `running` → `completed | partial_failure | failed`
- [ ]	Log failed lines to UploadErrorEntry
- [ ]	On success: mark hashlist/campaign as available

#### 🌐 API Endpoints
- [ ]	`POST /api/v1/web/uploads/`
    -	Accept file upload
    -	Triggers background task
- [ ]	`GET /api/v1/web/uploads/{id}/status`
    -	Returns:
    -	`status`, `started_at`, `finished_at`
	-	`error_count`
- [ ]	`GET /api/v1/web/uploads/{id}/errors` - Returns list of failed lines (paginated) (derive from `PaginatedResponse` in `app.schemas.shared`)

#### 🧪 Tests
- [ ]	Unit tests for plugin interface and dispatcher
- [ ]	Hash parser + inference tests (use `HashGuessService` from `app.core.services.hash_guess_service`)
- [ ]	Integration test: full upload flow with synthetic data
- [ ]	Permission test: Only allow upload for authenticated users

#### 🔐 Security & Hardening
- [ ]	Sanitize file names and restrict extensions (`shadow`, `.pdf`, `.zip`, `.7z`, `.docx`, etc.)
- [ ]	Set upload size limit (e.g., 100 MB)
- [ ]	Disable network access in plugins (plugin runner should be subprocess-isolated or use restricted Python execution)
- [ ]	Escape all user-visible error lines in UI

#### 🧩 UI Integration Prep
- [ ]	Define structure for status polling (`/api/v1/web/uploads/{id}/status`) - This should return the status of the upload task, including the hash type, extracted preview, and validation state. It should also return the ID of the uploaded resource file, along with an upload task ID that can be used to view the new upload processing progress in the UI. Status information and task completion information should be returned for each step of the upload and processing process to reflect the current state in the UI.
- [ ]	Ensure error lines are returned in full with line number + reason - This should be displayed in the UI when the `GET /api/v1/web/uploads/{id}/errors` endpoint is called. It should be a list of `UploadErrorEntry` objects that are paginated (derive from `PaginatedResponse` in `app.schemas.shared`)
- [ ]	Add status to Campaign and HashList models: `is_unavailable` - This should be used to indicate that the hash list and campaign are still being processed and are not ready to be used. This should default to `False` for new campaigns and hash lists, but should be set to `True` only when created by the crackable upload task and reverted to `False` when the processing is complete.